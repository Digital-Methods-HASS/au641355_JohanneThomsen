---
title: "Police_killings_Myattempt"
author: "Johanne"
date: "2022-12-05"
output: html_document
---

#NOTE!
##THE GRAPHS I MADE STARTS FROM LINE 145!
### YOU DO NEED TO RUN ALL THE FOLLOWING CHUNKS THOUGH

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Challenge
The data resides in a HTML table that has notoriously messy headers and tags. There is one table for each individual year. Look and weep:
!["Killed by police website with html source"](./readme-figs/Killed_html.png)

# Solution
First, install a handful of classic R packages and load their libraries:

- `rvest` for web-scraping
- `dplyr` for data-wrangling
- `tidyr` for data transformation
- `stringr` for string manipulation
- `janitor` for clean headers that your OCD will love you for


```{r libraries, warning=FALSE, message=FALSE}
library(rvest)
library(dplyr)
library(tidyr)
library(stringr)
library(janitor)
```

## Scrape the data

Next, learn how scrape the content of the website and extract the HTML table:
```{r url}
url <- "http://web.archive.org/web/20200502072010/https://killedbypolice.net/kbp2020"
# scrape the website
url_html <- read_html(url)
```

Extract the whole HTML table through the <table> tag. Well, to be precise it loads the html table into a list not a dataframe, but we can unlist the resulting list and coerce it into a dataframe, and that's less work than options 1 and 2 above, so vaersgo!

```{r scrape-table}
whole_table <- url_html %>% 
 html_nodes("table") %>%
 html_table()  #str(whole_table) turns out to be a list
str(whole_table)
whole_table[[1]]
whole_table
```

```{r html-to-df}
new_table <- do.call(cbind,unlist(whole_table, recursive = FALSE)) 
head(new_table)
```

## Automate the scraping!
```{r scrape-function}
scrape_police_kill <- function(website){
	url <- read_html(website)
	annual_table <- url %>% 
 			html_nodes("table") %>%
 			html_table()  # result is a list
  annual_table <- do.call(cbind,unlist(annual_table, recursive = FALSE))
 }

# Test that the function works on year 2018

table2018 <- scrape_police_kill("https://killedbypolice.net/kbp2018")
table2018 %>% 
	head()
```

```{r loop}
# Create a container for the results
mastertable=NULL  # we need to create an empty container

# Loop over the years to iterate the scraping
for (year in 2013:2020){  
	print(year) # let's check which year we are in
	url <- "http://web.archive.org/web/20200502072010/https://killedbypolice.net/kbp"   # the annual URLs end with "kbp2017" ,etc., so make sure to strip the year so it can be replaced
	website <- paste0(url,year)  # here we bind the year to the website to form the URL
	annual_table <- scrape_police_kill(website) # here we apply the scraping function
	mastertable <- rbind(mastertable, annual_table) # we add the scraped results from the given year to our master dataset
	}
head(mastertable,2)
tail(mastertable)
```

## Cleaning scraped data
```{r clean-data}
mastertable <- as_tibble(mastertable)
str(mastertable)
```

```{r wrangle-columns, message = FALSE, warning=FALSE}
library(tidyverse)
data <- mastertable %>% 
	mutate(Age = as.numeric(Age))  %>% 
	rename(Method = "*") 
```

```{r check-dates}
mastertable$Date[c(30:40, 70:80)]
tail(unique(mastertable$Date))
```

```{r clean-dates, warning = FALSE}
library(lubridate)

# Adapt this pipeline to any other inconsistent dates you discover
data <- data %>%
	mutate(Date =
			case_when(
				grepl("201[34]", Date) ~ mdy(Date),
				# convert dates that contain 2013 or 2014 into mdy format
				!grepl("201[34]",Date) ~ ymd(Date)),
					Year = year(Date))
				# convert all other dates ymd format

# Create a new column called "Year" from the Date for plotting
# data <- data %>% 
# 	mutate(Year = year(Date))  

tail(data$Year)
class(data$Date)
class(data$Year)
length(which(is.na(data$Date)))
length(which(is.na(data$Year)))

```

### Write result to file
```{r write-to-csv}
write_csv(data,"policekillings2022.csv")
```



#MY TURN!
#I want to try figuring out what methods are more frequent in the killings people of various race. Since we already know from previous graph that some of the most frequent methods in general are G (gun), K (knife?), N (?) and V (vehicle), I am going to focus on those.

#First, I made a graph showing the four methods of killing in for blacks, latinos and whites, respectively, throughout the years. So that we can see that the method of killing of blacks in 2013 was 100% gun, whereas that number was a bit smaller for latinos and whites.

```{r plot-my_attemt}
library(tidyverse)
library(ggplot2)

data <- read_csv("policekillings2022.csv")

data %>% 
  filter(!is.na(Year)) %>% 
  filter(Method %in% c("G", "K", "N", "V")) %>% 
  filter(Race %in% c("W", "B", "L")) %>% 
  group_by(Year, 
           Race,
           Method) %>% 
  tally() %>% 
  mutate(perc = n / sum(n) * 100)  %>%
  ggplot(aes(x = Method,
             y = perc,
             fill = Race)) +
  geom_col() +
  facet_grid(Race~Year) +
  theme_minimal(base_size = 10) +
  xlab("Method of killing") +
  ylab("Percentage of all\npeople killed by police\nby race") 
```

# I decided to make a second graph, which, instead of comparing the killings throughout the years, shows all the killings of the four weapons throughout 2013-2020 with the three races showed side-by-side. This is therefore better, if you want to compare the killings of the three races in general

```{r}
library(ggplot2)

data %>% 
  filter(!is.na(Year)) %>% 
  filter(Method %in% c("G", "K", "N", "V")) %>% 
  filter(Race %in% c("W", "B", "L")) %>%
  group_by(Race,
           Method) %>% 
  tally() %>% 
  mutate(Percent = n / sum(n) * 100)  %>% 
  ggplot(aes(x = Method,
             y = Percent,
             fill = Race)) + 
    geom_bar(position="dodge", stat="identity") +
  scale_y_continuous(breaks = seq(0, 100, 10),
                     labels = seq(0, 100, 10)) +
  theme_minimal(base_size = 10) +
  labs(y = "Percentage of all\npeople killed by police\nby race",
       x = "Method of killing")
```